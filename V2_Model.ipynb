{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb6f68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 250\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load your fine-tune CSV\n",
    "df = pd.read_csv(\"Resources/Preprocessed dataset.csv\")\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfb9274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I constantly feel like I am worthless and a burden to others.\n",
      "2. I constantly feel like I am worthless and a burden to others.\n",
      "3. I frequently think about ending everything, I donâ€™t see a way out.\n",
      "4. I constantly feel like I am worthless and a burden to others.\n",
      "5. I am always exhausted, even talking feels like too much effort.\n",
      "6. People tell me I seem lifeless or that I barely move anymore.\n",
      "7. I feel empty and disconnected from everything, like life is meaningless.\n",
      "8. I frequently think about ending everything, I donâ€™t see a way out.\n",
      "9. I barely sleep at night, and when I do, nightmares wake me up. [/INST] PHQ-9 Score: 26\n",
      "Depression Level: Severe</s>\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import json\n",
    "\n",
    "# Load your dataset from CSV\n",
    "dataset = load_dataset(\"csv\", data_files=\"Resources\\Preprocessed dataset.csv\")[\"train\"]\n",
    "# if JSONL:\n",
    "# dataset = load_dataset(\"json\", data_files=\"Output_dir/Preprocessed_dataset.jsonl\")[\"train\"]\n",
    "\n",
    "# Step 2: Define safe format function\n",
    "def format_example(example):\n",
    "    instruction = \"Analyze the following PHQ-9 responses and provide the score and depression level.\"\n",
    "\n",
    "    # Skip if input or output is None or empty\n",
    "    if not example.get('input') or not example.get('output'):\n",
    "        return {\"text\": None}\n",
    "\n",
    "    user_input = example['input'].strip()\n",
    "    output = example['output'].strip()\n",
    "    full_prompt = f\"<s>[INST] {instruction}\\n\\n{user_input} [/INST] {output}</s>\"\n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "# Step 3: Apply formatting\n",
    "formatted_dataset = dataset.map(format_example)\n",
    "\n",
    "# Step 4: Remove bad/null entries\n",
    "formatted_dataset = formatted_dataset.filter(lambda x: x[\"text\"] is not None)\n",
    "\n",
    "# (Optional) Preview\n",
    "print(formatted_dataset[0][\"text\"])\n",
    "\n",
    "# Step 5: Save to disk\n",
    "#output_path = \"Output_dir/formatted_mental_health_dataset.jsonl\"\n",
    "#with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#   for example in formatted_dataset:\n",
    "#        json.dump({\"text\": example[\"text\"]}, f)\n",
    "#       f.write(\"\\n\")\n",
    "\n",
    "#print(f\"\\nâœ… Saved cleaned and formatted dataset to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a018b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0905 13:15:08.507000 12648 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from huggingface_hub import login\n",
    "import key_param     \n",
    "hf_token = key_param.mistral_api_hf\n",
    "login(token=hf_token)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\", token=hf_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize_function(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    # Create labels by copying input_ids and replacing pad tokens with -100\n",
    "    labels = [\n",
    "        -100 if token == tokenizer.pad_token_id else token\n",
    "        for token in tokenized[\"input_ids\"]\n",
    "    ]\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "tokenized_dataset = formatted_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08aeac44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db2b257613f41a281bacf8b43aea862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from huggingface_hub import login\n",
    "import key_param\n",
    "\n",
    "# Login\n",
    "hf_token = key_param.mistral_api_hf\n",
    "login(token=hf_token)\n",
    "\n",
    "# Model ID\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=hf_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None,  # Load everything on CPU first (no meta)\n",
    "    low_cpu_mem_usage=False,\n",
    "    \n",
    ")\n",
    "\n",
    "#model = model.to(device)\n",
    "\n",
    "# (Optional) Only call prepare_model_for_kbit_training if doing k-bit training\n",
    "# model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Now all parameters should be on device and not meta\n",
    "for name, param in model.named_parameters():\n",
    "    if param.device.type == \"meta\":\n",
    "        print(f\"Meta param still found: {name}\")\n",
    "\n",
    "# Continue with training...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a125de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.device.type == 'meta':\n",
    "        print(f\"Parameter {name} is still on meta!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a8a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8850c2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle full dataset\n",
    "full_dataset = tokenized_dataset.shuffle(seed=42)\n",
    "\n",
    "# Select 100k for training\n",
    "tokenized_train = full_dataset.select(range(240))\n",
    "\n",
    "# Select 50k for evaluation (from after 150k)\n",
    "tokenized_eval = full_dataset.select(range(240, 250))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dbdab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"TORCH_NAN_CHECK\"] = \"0\"\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "model.gradient_checkpointing_enable()  # keep for memory efficiency\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./mistral-model-epoch-15\",   # new folder\n",
    "    logging_dir=\"./logs\",  \n",
    "    per_device_train_batch_size=2,          # use 2 since dataset is small\n",
    "    gradient_accumulation_steps=1,          # no need to accumulate with tiny data\n",
    "    num_train_epochs=10,                    # train more epochs to learn from small dataset\n",
    "    learning_rate=5e-5,                     # default good LR\n",
    "    fp16=True,                              # use mixed precision if GPU supports\n",
    "    optim=\"adamw_torch\",                    # normal AdamW is fine\n",
    "    save_strategy=\"epoch\",                  # save after each epoch\n",
    "    save_total_limit=1,                     # keep only the last checkpoint\n",
    "    logging_steps=10,                       # log more frequently\n",
    "    logging_first_step=True,\n",
    "    report_to=\"none\",                       # no external logging\n",
    "    gradient_checkpointing=True             # memory efficient\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3caa9a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 13:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.192200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.535500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.404600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.298500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.272700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.276800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.254700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.245400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.219200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.234200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.213300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.212300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.206600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.204800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.197400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.205700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.188500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.190900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.205900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.199700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.194200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.198400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.190800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.200300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.192600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.189900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.184100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.179300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.179800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.173300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.169900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.177700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.169400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.170900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.171000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.176900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.166400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.157600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.159300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.156200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.154900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Training Loss: 4.688900\n",
      "Step 10 - Training Loss: 4.440600\n",
      "Step 20 - Training Loss: 2.096400\n",
      "Step 30 - Training Loss: 1.192200\n",
      "Step 40 - Training Loss: 0.792500\n",
      "Step 50 - Training Loss: 0.640600\n",
      "Step 60 - Training Loss: 0.535500\n",
      "Step 70 - Training Loss: 0.404600\n",
      "Step 80 - Training Loss: 0.396300\n",
      "Step 90 - Training Loss: 0.337300\n",
      "Step 100 - Training Loss: 0.298500\n",
      "Step 110 - Training Loss: 0.272700\n",
      "Step 120 - Training Loss: 0.276800\n",
      "Step 130 - Training Loss: 0.254200\n",
      "Step 140 - Training Loss: 0.260600\n",
      "Step 150 - Training Loss: 0.249000\n",
      "Step 160 - Training Loss: 0.254700\n",
      "Step 170 - Training Loss: 0.252000\n",
      "Step 180 - Training Loss: 0.244400\n",
      "Step 190 - Training Loss: 0.235600\n",
      "Step 200 - Training Loss: 0.247400\n",
      "Step 210 - Training Loss: 0.245400\n",
      "Step 220 - Training Loss: 0.241800\n",
      "Step 230 - Training Loss: 0.230600\n",
      "Step 240 - Training Loss: 0.219200\n",
      "Step 250 - Training Loss: 0.223500\n",
      "Step 260 - Training Loss: 0.217200\n",
      "Step 270 - Training Loss: 0.215500\n",
      "Step 280 - Training Loss: 0.234200\n",
      "Step 290 - Training Loss: 0.227400\n",
      "Step 300 - Training Loss: 0.223000\n",
      "Step 310 - Training Loss: 0.222500\n",
      "Step 320 - Training Loss: 0.216200\n",
      "Step 330 - Training Loss: 0.211000\n",
      "Step 340 - Training Loss: 0.213300\n",
      "Step 350 - Training Loss: 0.212300\n",
      "Step 360 - Training Loss: 0.213700\n",
      "Step 370 - Training Loss: 0.206600\n",
      "Step 380 - Training Loss: 0.211000\n",
      "Step 390 - Training Loss: 0.214000\n",
      "Step 400 - Training Loss: 0.208600\n",
      "Step 410 - Training Loss: 0.201300\n",
      "Step 420 - Training Loss: 0.204800\n",
      "Step 430 - Training Loss: 0.208500\n",
      "Step 440 - Training Loss: 0.209000\n",
      "Step 450 - Training Loss: 0.202000\n",
      "Step 460 - Training Loss: 0.197400\n",
      "Step 470 - Training Loss: 0.210000\n",
      "Step 480 - Training Loss: 0.205700\n",
      "Step 490 - Training Loss: 0.188500\n",
      "Step 500 - Training Loss: 0.199600\n",
      "Step 510 - Training Loss: 0.192700\n",
      "Step 520 - Training Loss: 0.197000\n",
      "Step 530 - Training Loss: 0.190900\n",
      "Step 540 - Training Loss: 0.203800\n",
      "Step 550 - Training Loss: 0.205900\n",
      "Step 560 - Training Loss: 0.199700\n",
      "Step 570 - Training Loss: 0.193000\n",
      "Step 580 - Training Loss: 0.208400\n",
      "Step 590 - Training Loss: 0.194200\n",
      "Step 600 - Training Loss: 0.198400\n",
      "Step 610 - Training Loss: 0.189300\n",
      "Step 620 - Training Loss: 0.190800\n",
      "Step 630 - Training Loss: 0.182600\n",
      "Step 640 - Training Loss: 0.200300\n",
      "Step 650 - Training Loss: 0.188200\n",
      "Step 660 - Training Loss: 0.202100\n",
      "Step 670 - Training Loss: 0.186600\n",
      "Step 680 - Training Loss: 0.192600\n",
      "Step 690 - Training Loss: 0.186800\n",
      "Step 700 - Training Loss: 0.194500\n",
      "Step 710 - Training Loss: 0.193400\n",
      "Step 720 - Training Loss: 0.189900\n",
      "Step 730 - Training Loss: 0.187400\n",
      "Step 740 - Training Loss: 0.185100\n",
      "Step 750 - Training Loss: 0.184100\n",
      "Step 760 - Training Loss: 0.179300\n",
      "Step 770 - Training Loss: 0.184000\n",
      "Step 780 - Training Loss: 0.179800\n",
      "Step 790 - Training Loss: 0.184000\n",
      "Step 800 - Training Loss: 0.188300\n",
      "Step 810 - Training Loss: 0.181100\n",
      "Step 820 - Training Loss: 0.183000\n",
      "Step 830 - Training Loss: 0.181700\n",
      "Step 840 - Training Loss: 0.186100\n",
      "Step 850 - Training Loss: 0.173300\n",
      "Step 860 - Training Loss: 0.179400\n",
      "Step 870 - Training Loss: 0.169900\n",
      "Step 880 - Training Loss: 0.177700\n",
      "Step 890 - Training Loss: 0.175100\n",
      "Step 900 - Training Loss: 0.180200\n",
      "Step 910 - Training Loss: 0.169400\n",
      "Step 920 - Training Loss: 0.170900\n",
      "Step 930 - Training Loss: 0.171000\n",
      "Step 940 - Training Loss: 0.181900\n",
      "Step 950 - Training Loss: 0.176900\n",
      "Step 960 - Training Loss: 0.175100\n",
      "Step 970 - Training Loss: 0.173000\n",
      "Step 980 - Training Loss: 0.164000\n",
      "Step 990 - Training Loss: 0.167800\n",
      "Step 1000 - Training Loss: 0.164500\n",
      "Step 1010 - Training Loss: 0.157500\n",
      "Step 1020 - Training Loss: 0.172100\n",
      "Step 1030 - Training Loss: 0.168300\n",
      "Step 1040 - Training Loss: 0.166400\n",
      "Step 1050 - Training Loss: 0.164900\n",
      "Step 1060 - Training Loss: 0.166300\n",
      "Step 1070 - Training Loss: 0.162300\n",
      "Step 1080 - Training Loss: 0.172700\n",
      "Step 1090 - Training Loss: 0.154100\n",
      "Step 1100 - Training Loss: 0.159100\n",
      "Step 1110 - Training Loss: 0.157200\n",
      "Step 1120 - Training Loss: 0.163900\n",
      "Step 1130 - Training Loss: 0.157600\n",
      "Step 1140 - Training Loss: 0.157400\n",
      "Step 1150 - Training Loss: 0.160500\n",
      "Step 1160 - Training Loss: 0.159300\n",
      "Step 1170 - Training Loss: 0.156800\n",
      "Step 1180 - Training Loss: 0.157500\n",
      "Step 1190 - Training Loss: 0.156200\n",
      "Step 1200 - Training Loss: 0.154900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1200, training_loss=0.27183645476897556, metrics={'train_runtime': 831.3003, 'train_samples_per_second': 2.887, 'train_steps_per_second': 1.444, 'total_flos': 5.24737931378688e+16, 'train_loss': 0.27183645476897556})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "# Set pad_token to eos_token (required for decoder-only models like Mistral)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# # Tokenize function\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(\n",
    "#         example[\"text\"],\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         max_length=512\n",
    "#     )\n",
    "\n",
    "# # Apply tokenization\n",
    "# tokenized_dataset = small_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    " # Define collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# Initialize SFTTrainer without max_seq_length\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "class PrintLossCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None and \"loss\" in logs:\n",
    "            print(f\"Step {state.global_step} - Training Loss: {logs['loss']:.6f}\")\n",
    "\n",
    "# Then pass this callback to your trainer:\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train,\n",
    "   # eval_dataset=tokenized_eval,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "   # compute_metrics=compute_metrics,\n",
    "    callbacks=[PrintLossCallback()]\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bba481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LoRA adapter to ./mistral-model-epoch-15-lora-adapter\n"
     ]
    }
   ],
   "source": [
    "adapter_dir = \"./mistral-model-epoch-15-lora-adapter\"\n",
    "model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "print(f\"Saved LoRA adapter to {adapter_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd6251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5854999a12dd4f4d87368f4940462ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LoRA model loaded in 4-bit mode\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "adapter_dir = \"./mistral-model-epoch-15-lora-adapter\"\n",
    "base_model = \"mistralai/Mistral-7B-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_dir)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,   # âœ… use 4-bit instead of 8-bit\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "\n",
    "print(\"âœ… LoRA model loaded in 4-bit mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c29ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde36da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0905 13:35:33.174000 29344 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "c:\\Users\\deie\\anaconda3\\envs\\group52\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b898d33bab64f4fa478e2d6062d900b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deie\\anaconda3\\envs\\group52\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:1001: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged model saved at ./Output_dir/mistral-model-epoch-15-full-model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from huggingface_hub import login\n",
    "import key_param\n",
    "import os\n",
    "\n",
    "# ðŸ”‘ Login to HuggingFace\n",
    "hf_token = key_param.mistral_api_hf\n",
    "login(token=hf_token)\n",
    "\n",
    "# Paths\n",
    "adapter_dir = \"./mistral-model-epoch-15-lora-adapter\"   # your LoRA checkpoint\n",
    "output_dir = \"./Output_dir/mistral-model-epoch-15-full-model\"\n",
    "\n",
    "# âœ… Base model\n",
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "\n",
    "# Load base model in FP16 on CPU (safe for merging)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\",\n",
    "    use_auth_token=hf_token\n",
    ")\n",
    "\n",
    "# Load LoRA adapter on top of base model\n",
    "peft_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    adapter_dir,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "# âœ… Merge LoRA weights into the base model\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "\n",
    "# Save merged full model + tokenizer\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "merged_model.save_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"âœ… Merged model saved at {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b11e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0905 13:39:15.974000 36572 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaed0fbaa357487099bd028e3264f51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Path to your merged model\n",
    "output_dir = \"./Output_dir/mistral-model-epoch-15-full-model\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    device_map=\"auto\",        # use GPU if available\n",
    "    torch_dtype=torch.float16 # keep memory low\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42db712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Output ===\n",
      "Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. Little interest or pleasure in doing things\n",
      "2. Feeling down, depressed, or hopeless\n",
      "3. Trouble falling or staying asleep, or sleeping too much\n",
      "4. Feeling tired or having little energy\n",
      "5. Poor appetite or overeating\n",
      "6. Feeling bad about yourself\n",
      "7. Trouble concentrating on things\n",
      "8. Moving or speaking slowly / being restless\n",
      "9. Thoughts that you would be better off dead \n",
      "\n",
      "Answers: 0, 0, 0, 0, 0, 0, 0, 0, 0. Score = 0. No depression.\n",
      "\n",
      "1. Feeling down, depressed, or hopeless\n",
      "2. Feeling tired or having little energy\n",
      "3. Feeling tired or having little energy\n",
      "4. Trouble concentrating on things\n",
      "5. Feeling tired or having little energy\n",
      "6. Feeling tired or having little energy\n",
      "7. Feeling tired or having little energy\n",
      "8. Moving or speaking slowly / being restless\n",
      "9. Thoughts that you would be better off dead â†©\n",
      "\n",
      "Answers: 2, 2, 2, 2, 2, 2, 2, 0, 0. Score = 13. Moderate depression.\n",
      "\n",
      "### Moderate depression\n",
      "\n",
      "A score of 10 to\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example: pick one of your test inputs\n",
    "test_input = \"\"\"1. Little interest or pleasure in doing things\n",
    "2. Feeling down, depressed, or hopeless\n",
    "3. Trouble falling or staying asleep, or sleeping too much\n",
    "4. Feeling tired or having little energy\n",
    "5. Poor appetite or overeating\n",
    "6. Feeling bad about yourself\n",
    "7. Trouble concentrating on things\n",
    "8. Moving or speaking slowly / being restless\n",
    "9. Thoughts that you would be better off dead\"\"\"\n",
    "\n",
    "# Build prompt (same format used during training)\n",
    "instruction = \"Analyze the following PHQ-9 responses and provide the score and depression level.\"\n",
    "prompt = f\"<s>[INST] {instruction}\\n\\n{test_input} [/INST]\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "print(\"\\n=== Model Output ===\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412cfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1332a8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Test Sample 240\n",
      "Input: 1. I occasionally feel uninterested in activities I usually enjoy.\n",
      "2. I have slight trouble falling asleep but not every ...\n",
      "Expected: PHQ-9 Score: 5\n",
      "Depression Level: Mild\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I occasionally feel uninterested in activities I usually enjoy.\n",
      "2. I have slight trouble falling asleep but not every night.\n",
      "3. I feel a little more tired than usual, but I manage.\n",
      "4. I occasionally feel uninterested in activities I usually enjoy.\n",
      "5. I get distracted easily but can regain focus quickly.\n",
      "6. I occasionally feel uninterested in activities I usually enjoy.\n",
      "7. I occasionally feel uninterested in activities I usually enjoy.\n",
      "8. I feel a little more tired than usual, but I manage.\n",
      "9. No serious thoughts, just moments of feeling overwhelmed. \n",
      "\n",
      "Answer: 7\n",
      "\n",
      "Depression Level: Mild\n",
      "\n",
      "PHQ-9 scores of 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20 or above indicate moderate to severe depression.\n",
      "\n",
      "Answer Explanation:\n",
      "\n",
      "PHQ-9 scores of 0-4 indicate no depression, 5-9 indicate mild depression, 10-14 indicate moderate depression, 15-19 indicate moderately severe depression, and 20 or above indicate severe depression. The patientâ€™s responses indicate a mild depression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Test Sample 241\n",
      "Input: 1. Sleeping has become inconsistent, I either sleep too much or too little.\n",
      "2. My eating habits have changed significant ...\n",
      "Expected: PHQ-9 Score: 12\n",
      "Depression Level: Moderate\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. Sleeping has become inconsistent, I either sleep too much or too little.\n",
      "2. My eating habits have changed significantly, sometimes I skip meals.\n",
      "3. I donâ€™t enjoy activities like I used to, I force myself to do things.\n",
      "4. I donâ€™t enjoy activities like I used to, I force myself to do things.\n",
      "5. I struggle to concentrate on my assignments and lose track easily.\n",
      "6. I feel like I am not good enough, and it bothers me a lot.\n",
      "7. Feeling down most days, like nothing makes me happy anymore.\n",
      "8. I sometimes think about disappearing, but I wouldnâ€™t act on it.\n",
      "9. Sleeping has become inconsistent, I either sleep too much or too little.  I feel tired all the time, even after sleeping.\n",
      "\n",
      "The patientâ€™s PHQ-9 score is 14, which indicates moderate depression. The patient is experiencing several symptoms of depression, such as sleep disturbances, changes in eating habits, loss of interest in activities, difficulty concentrating, low self-esteem, and suicidal ideation. These symptoms are affecting the patientâ€™s daily functioning and quality of life. Moderate depression is a serious condition that requires professional help and treatment. The patient should seek help from a mental health professional who can provide appropriate treatment options and support. The treatment plan may include medication, psychotherapy, or a combination of both. It is essential to address the patientâ€™s symptoms promptly to prevent them from worsening and to improve their quality of life.\n",
      "\n",
      "ðŸ”¹ Test Sample 242\n",
      "Input: 1. I struggle to concentrate on my assignments and lose track easily.\n",
      "2. Sleeping has become inconsistent, I either slee ...\n",
      "Expected: PHQ-9 Score: 11\n",
      "Depression Level: Moderate\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I struggle to concentrate on my assignments and lose track easily.\n",
      "2. Sleeping has become inconsistent, I either sleep too much or too little.\n",
      "3. My eating habits have changed significantly, sometimes I skip meals.\n",
      "4. People say I seem slower in responding and doing things.\n",
      "5. I feel like I am not good enough, and it bothers me a lot.\n",
      "6. I struggle to concentrate on my assignments and lose track easily.\n",
      "7. Feeling down most days, like nothing makes me happy anymore.\n",
      "8. I donâ€™t enjoy activities like I used to, I force myself to do things.\n",
      "9. I sometimes think about disappearing, but I wouldnâ€™t act on it.  PHQ-9 Scoring and Interpretation\n",
      "\n",
      "For each of the nine DSM-5 criteria below, give yourself the score listed for how often you have been experiencing that problem in the last two weeks.\n",
      "\n",
      "0 = Not at all\n",
      "\n",
      "1 = Several days\n",
      "\n",
      "2 = More than half the days\n",
      "\n",
      "3 = Nearly every day\n",
      "\n",
      "Depression Level\n",
      "\n",
      "0-4: Minimal Level\n",
      "\n",
      "5-9: Mild\n",
      "\n",
      "10-14: Moderate\n",
      "\n",
      "15-19: Moderate to Severe\n",
      "\n",
      "20+: Severe\n",
      "\n",
      "Depression Scale\n",
      "\n",
      "1. Feeling down, or having a depressed mood\n",
      "2. Feeling tired or having little energy\n",
      "3. Poor appetite or weight loss\n",
      "4. Poor appetite or weight gain\n",
      "5. Insomnia or hypersomnia (excessive sleeping)\n",
      "6. Poor concentration, or difficulty focusing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "# Load your dataset again\n",
    "df = pd.read_csv(\"Resources/Preprocessed dataset.csv\")\n",
    "\n",
    "# Select test range (240â€“249)\n",
    "test_df = df.iloc[240:243]\n",
    "\n",
    "# Test loop\n",
    "for i, row in test_df.iterrows():\n",
    "    instruction = row[\"instruction\"]\n",
    "    user_input = row[\"input\"]\n",
    "    expected_output = row[\"output\"]\n",
    "\n",
    "    # Build prompt (same as training format)\n",
    "    prompt = f\"<s>[INST] {instruction}\\n\\n{user_input} [/INST]\"\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate model prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Test Sample {i}\")\n",
    "    print(\"Input:\", user_input[:120], \"...\")\n",
    "    print(\"Expected:\", expected_output)\n",
    "    print(\"Predicted:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd479db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0905 12:23:31.029000 15348 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75bd1bde77145328dfe89cc0409ce9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 240\n",
      "Expected: PHQ-9 Score: 5\n",
      "Depression Level: Mild\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I occasionally feel uninterested in activities I usually enjoy.\n",
      "2. I have slight trouble falling asleep but not every night.\n",
      "3. I feel a little more tired than usual, but I manage.\n",
      "4. I occasionally feel uninterested in activities I usually enjoy.\n",
      "5. I get distracted easily but can regain focus quickly.\n",
      "6. I occasionally feel uninterested in activities I usually enjoy.\n",
      "7. I occasionally feel uninterested in activities I usually enjoy.\n",
      "8. I feel a little more tired than usual, but I manage.\n",
      "9. No serious thoughts, just moments of feeling overwhelmed. \n",
      "10. I occasionally feel uninterested in activities I usually enjoy.\n",
      "\n",
      "PHQ-9 Score: 10\n",
      "\n",
      "Depression Level: Moderate\n",
      "\n",
      "Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I occasionally feel uninterested in activities I usually enjoy.\n",
      "2. I occasionally feel uninterested in activities I usually enjoy.\n",
      "3. I occasionally feel uninterested in activities I usually enjoy.\n",
      "4. I occasionally feel uninterested in activities I usually enjoy.\n",
      "5. I occasionally feel uninterested in activities I usually enjoy.\n",
      "6. I occasionally feel uninterested in activities I usually enjoy.\n",
      "7. I occasionally feel uninterested in activities I usually enjoy.\n",
      "8. I occasionally feel uninterested in activities I usually enjoy.\n",
      "9. I occasionally feel uninterested in activities I usually enjoy.\n",
      "10. I occasionally feel uninter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 241\n",
      "Expected: PHQ-9 Score: 12\n",
      "Depression Level: Moderate\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. Sleeping has become inconsistent, I either sleep too much or too little.\n",
      "2. My eating habits have changed significantly, sometimes I skip meals.\n",
      "3. I donâ€™t enjoy activities like I used to, I force myself to do things.\n",
      "4. I donâ€™t enjoy activities like I used to, I force myself to do things.\n",
      "5. I struggle to concentrate on my assignments and lose track easily.\n",
      "6. I feel like I am not good enough, and it bothers me a lot.\n",
      "7. Feeling down most days, like nothing makes me happy anymore.\n",
      "8. I sometimes think about disappearing, but I wouldnâ€™t act on it.\n",
      "9. Sleeping has become inconsistent, I either sleep too much or too little. .\n",
      "\n",
      "The PHQ-9 score is 15, which indicates severe depression.\n",
      "\n",
      "Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I feel like I am not good enough, and it bothers me a lot.\n",
      "2. I feel tired all the time, like I canâ€™t get enough sleep.\n",
      "3. I feel like I am not good enough, and it bothers me a lot.\n",
      "4. I feel like I am not good enough, and it bothers me a lot.\n",
      "5. I feel like I am not good enough, and it bothers me a lot.\n",
      "6. I feel like I am not good enough, and it bothers me a lot.\n",
      "7. I feel like I am not good enough, and it bothers me a lot.\n",
      "8. I feel like I am not good enough, and it bothers me a lot.\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 242\n",
      "Expected: PHQ-9 Score: 11\n",
      "Depression Level: Moderate\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I struggle to concentrate on my assignments and lose track easily.\n",
      "2. Sleeping has become inconsistent, I either sleep too much or too little.\n",
      "3. My eating habits have changed significantly, sometimes I skip meals.\n",
      "4. People say I seem slower in responding and doing things.\n",
      "5. I feel like I am not good enough, and it bothers me a lot.\n",
      "6. I struggle to concentrate on my assignments and lose track easily.\n",
      "7. Feeling down most days, like nothing makes me happy anymore.\n",
      "8. I donâ€™t enjoy activities like I used to, I force myself to do things.\n",
      "9. I sometimes think about disappearing, but I wouldnâ€™t act on it.  10. I feel like I am not good enough, and it bothers me a lot.\n",
      "\n",
      "The PHQ-9 score is 15, which indicates severe depression.\n",
      "\n",
      "The PHQ-9 is a valid and reliable tool for assessing the severity of depression in adults. The score of 15 indicates that the individual is experiencing severe depression, which is characterized by persistent feelings of sadness, loss of interest in activities, significant changes in appetite or weight, difficulty sleeping, fatigue, feelings of worthlessness or guilt, difficulty concentrating, and thoughts of suicide. Severe depression can have a significant impact on an individualâ€™s daily functioning and quality of life, and may require professional intervention and treatment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 243\n",
      "Expected: PHQ-9 Score: 1\n",
      "Depression Level: Minimal\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. No major changes in mood, I feel mostly okay.\n",
      "2. No noticeable change in movement or activity levels.\n",
      "3. I feel fine and enjoy my hobbies as usual.\n",
      "4. I feel fine and enjoy my hobbies as usual.\n",
      "5. No noticeable change in movement or activity levels.\n",
      "6. No major changes in mood, I feel mostly okay.\n",
      "7. No noticeable change in movement or activity levels.\n",
      "8. Sleeping well, no major issues with rest.\n",
      "9. No major changes in mood, I feel mostly okay. \n",
      "\n",
      "The PHQ-9 score is 5, which is within the normal range. The patient does not meet the criteria for depression.\n",
      "\n",
      "Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I feel like a failure and that nothing I do is worthwhile.\n",
      "2. I feel like a failure and that nothing I do is worthwhile.\n",
      "3. I feel like a failure and that nothing I do is worthwhile.\n",
      "4. I feel like a failure and that nothing I do is worthwhile.\n",
      "5. I feel like a failure and that nothing I do is worthwhile.\n",
      "6. I feel like a failure and that nothing I do is worthwhile.\n",
      "7. I feel like a failure and that nothing I do is worthwhile.\n",
      "8. I feel like a failure and that nothing I do is worthwhile.\n",
      "9. I feel like a failure and that nothing I do is worth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 244\n",
      "Expected: PHQ-9 Score: 20\n",
      "Depression Level: Severe\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I canâ€™t concentrate at all, I feel like my brain is shutting down.\n",
      "2. I frequently think about ending everything, I donâ€™t see a way out.\n",
      "3. I feel empty and disconnected from everything, like life is meaningless.\n",
      "4. I constantly feel like I am worthless and a burden to others.\n",
      "5. I am always exhausted, even talking feels like too much effort.\n",
      "6. I canâ€™t concentrate at all, I feel like my brain is shutting down.\n",
      "7. People tell me I seem lifeless or that I barely move anymore.\n",
      "8. I canâ€™t concentrate at all, I feel like my brain is shutting down.\n",
      "9. I constantly feel like I am worthless and a burden to others. . I frequently think about ending everything, I donâ€™t see a way out.\n",
      "\n",
      "The PHQ-9 score is 27, which indicates severe depression.\n",
      "\n",
      "The PHQ-9 is a widely used self-report measure of depression severity. It consists of nine items that assess the frequency of symptoms over the past two weeks on a scale of 0 (not at all) to 3 (nearly every day). The total score ranges from 0 to 27, with higher scores indicating more severe depression.\n",
      "\n",
      "In this case, the patient has scored 27 out of 27, indicating severe depression. Severe depression is characterized by persistent feelings of hopelessness, thoughts of suicide, and a significant impact on daily functioning. It is important to note that the PHQ-9 is not a diagnostic tool and should be used in conjunction with a clinical evaluation.\n",
      "\n",
      "The patientâ€™s responses indicate that they are experiencing severe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 245\n",
      "Expected: PHQ-9 Score: 9\n",
      "Depression Level: Mild\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I get distracted easily but can regain focus quickly.\n",
      "2. I get distracted easily but can regain focus quickly.\n",
      "3. No serious thoughts, just moments of feeling overwhelmed.\n",
      "4. Sometimes I feel down, but it doesn't last long.\n",
      "5. At times I feel I could do better, but it's not overwhelming.\n",
      "6. I occasionally feel uninterested in activities I usually enjoy.\n",
      "7. At times I feel I could do better, but it's not overwhelming.\n",
      "8. I fidget a little more than usual, but nothing extreme.\n",
      "9. At times I feel I could do better, but it's not overwhelming. \n",
      "10. I get distracted easily but can regain focus quickly.\n",
      "\n",
      "The PHQ-9 score is 10, which is in the mild range.\n",
      "\n",
      "Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I get distracted easily but can regain focus quickly.\n",
      "2. I get distracted easily but can regain focus quickly.\n",
      "3. No serious thoughts, just moments of feeling overwhelmed.\n",
      "4. Sometimes I feel I could do better, but it's not overwhelming.\n",
      "5. I occasionally feel uninterested in activities I usually enjoy.\n",
      "6. I occasionally feel uninterested in activities I usually enjoy.\n",
      "7. At times I feel I could do better, but it's not overwhelming.\n",
      "8. I occasionally feel uninterested in activities I usually enjoy.\n",
      "9. I occasionally feel uninterested in activities I usually enjoy. WIN\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 246\n",
      "Expected: PHQ-9 Score: 8\n",
      "Depression Level: Mild\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I feel a little more tired than usual, but I manage.\n",
      "2. I fidget a little more than usual, but nothing extreme.\n",
      "3. I fidget a little more than usual, but nothing extreme.\n",
      "4. I feel a little more tired than usual, but I manage.\n",
      "5. I feel a little more tired than usual, but I manage.\n",
      "6. Sometimes I feel down, but it doesn't last long.\n",
      "7. I occasionally feel uninterested in activities I usually enjoy.\n",
      "8. I fidget a little more than usual, but nothing extreme.\n",
      "9. No serious thoughts, just moments of feeling overwhelmed. \n",
      "10. I occasionally feel uninterested in activities I usually enjoy.\n",
      "\n",
      "PHQ-9 Score: 10\n",
      "\n",
      "Depression Level: Moderate\n",
      "\n",
      "Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I feel a little more tired than usual, but I manage.\n",
      "2. I fidget a little more than usual, but nothing extreme.\n",
      "3. I fidget a little more than usual, but nothing extreme.\n",
      "4. I feel a little more tired than usual, but I manage.\n",
      "5. I feel a little more tired than usual, but I manage.\n",
      "6. Sometimes I feel down, but it doesn't last long.\n",
      "7. I occasionally feel uninterested in activities I usually enjoy.\n",
      "8. I fidget a little more than usual, but nothing extreme.\n",
      "9. No serious thoughts, just moments of feeling overwhelmed.  |\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 247\n",
      "Expected: PHQ-9 Score: 1\n",
      "Depression Level: Minimal\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. No thoughts of self-harm or suicidal ideation.\n",
      "2. No noticeable change in movement or activity levels.\n",
      "3. I can focus well on my studies without distractions.\n",
      "4. No thoughts of self-harm or suicidal ideation.\n",
      "5. No major changes in mood, I feel mostly okay.\n",
      "6. No major changes in mood, I feel mostly okay.\n",
      "7. No thoughts of self-harm or suicidal ideation.\n",
      "8. Sleeping well, no major issues with rest.\n",
      "9. Eating habits are normal, no major appetite changes.  Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I can focus well on my studies without distractions.\n",
      "2. I can focus well on my studies without distractions.\n",
      "3. I can focus well on my studies without distractions.\n",
      "4. I can focus well on my studies without distractions.\n",
      "5. I can focus well on my studies without distractions.\n",
      "6. I can focus well on my studies without distractions.\n",
      "7. I can focus well on my studies without distractions.\n",
      "8. Sleeping well, no major issues with rest.\n",
      "9. Eating habits are normal, no major appetite changes.\n",
      "\n",
      "PHQ-9 Score: 0\n",
      "\n",
      "Depression Level: Minimal\n",
      "\n",
      "Explain why the PHQ-9 score is 0 and the depression level is minimal.\n",
      "\n",
      "Analyze the following PHQ-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Sample 248\n",
      "Expected: PHQ-9 Score: 0\n",
      "Depression Level: Minimal\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I feel confident in myself and my abilities.\n",
      "2. No thoughts of self-harm or suicidal ideation.\n",
      "3. Energy levels are good, I can do my daily tasks easily.\n",
      "4. I feel confident in myself and my abilities.\n",
      "5. Eating habits are normal, no major appetite changes.\n",
      "6. Eating habits are normal, no major appetite changes.\n",
      "7. I feel fine and enjoy my hobbies as usual.\n",
      "8. Eating habits are normal, no major appetite changes.\n",
      "9. No thoughts of self-harm or suicidal ideation. .\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9 score is 0, indicating no depression.\n",
      "\n",
      "The PHQ-9\n",
      "\n",
      "ðŸ”¹ Sample 249\n",
      "Expected: PHQ-9 Score: 20\n",
      "Depression Level: Severe\n",
      "Predicted: Analyze the following PHQ-9 responses and provide the score and depression level.\n",
      "\n",
      "1. I have no motivation to do anything, I just stay in bed all day.\n",
      "2. I am always exhausted, even talking feels like too much effort.\n",
      "3. I constantly feel like I am worthless and a burden to others.\n",
      "4. I canâ€™t concentrate at all, I feel like my brain is shutting down.\n",
      "5. People tell me I seem lifeless or that I barely move anymore.\n",
      "6. I have completely lost my appetite and have lost weight.\n",
      "7. People tell me I seem lifeless or that I barely move anymore.\n",
      "8. I feel empty and disconnected from everything, like life is meaningless.\n",
      "9. I have no motivation to do anything, I just stay in bed all day. \n",
      "\n",
      "The PHQ-9 score is 27, which indicates severe depression.\n",
      "\n",
      "The PHQ-9 is a widely used self-report measure of depression severity. It consists of nine items that assess the frequency of symptoms over the past two weeks on a scale of 0 (not at all) to 3 (nearly every day). The total score ranges from 0 to 27, with higher scores indicating more severe depression.\n",
      "\n",
      "In this case, the patient has scored 27 out of 27, indicating severe depression. Severe depression is characterized by persistent feelings of sadness, hopelessness, and worthlessness, as well as significant impairment in daily functioning. Individuals with severe depression may experience suicidal ideation or attempt suicide.\n",
      "\n",
      "It is important to note that the PHQ-9 is a self-report measure and should not be used as the sole basis for diagnosis or treatment. A mental health\n",
      "\n",
      "âœ… Depression Level Accuracy on Test Set: 10.00% (1/10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load merged model\n",
    "model_dir = \"./Output_dir/mistral-model-epoch-5-full-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Resources/Preprocessed dataset.csv\")\n",
    "test_df = df.iloc[240:250]\n",
    "\n",
    "correct = 0\n",
    "total = len(test_df)\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    instruction = row[\"instruction\"]\n",
    "    user_input = row[\"input\"]\n",
    "    expected_output = row[\"output\"]\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = f\"<s>[INST] {instruction}\\n\\n{user_input} [/INST]\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Extract depression level (expected format: \"Depression Level: XYZ\")\n",
    "    expected_level = re.search(r\"Depression Level:\\s*(.+)\", expected_output)\n",
    "    predicted_level = re.search(r\"Depression Level:\\s*(.+)\", prediction)\n",
    "\n",
    "    if expected_level and predicted_level:\n",
    "        expected_level = expected_level.group(1).strip()\n",
    "        predicted_level = predicted_level.group(1).strip()\n",
    "        if expected_level.lower() == predicted_level.lower():\n",
    "            correct += 1\n",
    "\n",
    "    print(f\"\\nðŸ”¹ Sample {i}\")\n",
    "    print(\"Expected:\", expected_output)\n",
    "    print(\"Predicted:\", prediction)\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f\"\\nâœ… Depression Level Accuracy on Test Set: {accuracy:.2f}% ({correct}/{total})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c23f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087701af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576fc0bcf620404d8cd2ec9135e05ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_path = \"./mistral-mentalhealth-full-model-100000\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=None  # disables auto-offload\n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8bd19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_CPP = r\"E:\\Group_52\\ChatApp\\LLMRagSystem\\Ollama\\llama.cpp\"\n",
    "HF_DIR    = r\"E:\\Group_52\\ChatApp\\LLMRagSystem\\mistral-mentalhealth-full-model-100000\"\n",
    "OUT_FP16  = r\"E:\\Group_52\\ChatApp\\LLMRagSystem\\mistral-mentalhealth-fp16.gguf\"\n",
    "OUT_Q4    = r\"E:\\Group_52\\ChatApp\\LLMRagSystem\\mistral-mentalhealth.Q4_K_M.gguf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7e60dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 14:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.8059\n",
      "Perplexity: 6.0854\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "# If you saved tokenized_eval earlier, you can load it like:\n",
    "# tokenized_eval = load_from_disk(\"./tokenized_eval_dataset\")\n",
    "# Otherwise, tokenize again\n",
    "# tokenized_eval = tokenizer([...], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "# ==============================\n",
    "# 3. Define Evaluation Arguments\n",
    "# ==============================\n",
    "eval_args = TrainingArguments(\n",
    "    output_dir=\"./eval_results\",\n",
    "    per_device_eval_batch_size=2,\n",
    "    fp16=True,\n",
    "    dataloader_drop_last=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 4. Create Trainer for Eval\n",
    "# ==============================\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=eval_args,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 5. Run Evaluation\n",
    "# ==============================\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "eval_loss = eval_results[\"eval_loss\"]\n",
    "perplexity = torch.exp(torch.tensor(eval_loss))\n",
    "\n",
    "print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
